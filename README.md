### Hi there ðŸ‘‹
<!--
- ðŸ”­ My research focuses on **AI Safety and Reliability**. Toward this goal, I am working on the intersection of self-supervision, generative modeling, spatial/temporal modeling for image/video understanding, label-efficient learning, adversarial attacks/defenses, out-of-distribution generalization, and privacy-preserving.
-->
<!--
- ðŸ”­ My research interests are robust perception to understand and explain AI behavior, temporal perception, self-learning, AI safety, and reliability.
-->
- ðŸ”­ I am interested in building Robust Intelligent Systems. My research focuses on robust visual-spatial and temporal perception, understanding and explaining AI behavior through adversarial machine learning, representation learning through self-learning ( self-supervision, self-distillation, self-critique, self-reflection), and configuring the role of large language models (LLMs) in building robust AI systems across applications of life sciences and security.
- ðŸŒ± You are welcome to explore my research work using the code provided below. Eight of the papers have been accepted as **Oral/Spotlight** at ICLR, NeurIPS, AAAI, CVPR, BMVC, and ACCV.
- ðŸ“« How to reach me: muz.pak@gmail.com

<!-- - ðŸ‘¯ Iâ€™m looking to collaborate on 
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ˜„ Pronouns: he/him/his

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=muzammal-naseer&theme=radical)
-->
:seedling: **Repositories**

|Topic|Application|Paper|Repo|Venue
|---|:---:|:---:|:---:|:---:|
Self-Learning | Volumetric Medical Segmentation | [DyCON: Dynamic Uncertainty-aware Consistency and Contrastive Learning for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2504.04566) | [DyCON](https://github.com/KU-CVML/DyCON)| CVPR'25|
Vision-Language Model | Understanding VLM's Generalization | [VANE-Bench: Video Anomaly Evaluation Benchmark for Conversational LMMs](https://arxiv.org/abs/2406.10326) | [VANE-Bench](https://github.com/rohit901/VANE-Bench) | NAACL'25|
Vision-Language Model | Prompt Learning without Visual Data | [Learning to Prompt with Text Only Supervision for Vision-Language Models](https://arxiv.org/abs/2401.02418) | [ProText](https://github.com/muzairkhattak/ProText) | AAAI'25|
Vision-Language Model | Agriculture and Livestock Representation Learning | [AgriCLIP: Adapting CLIP for Agriculture and Livestock via Domain-Specialized Cross-Model Alignment](https://arxiv.org/abs/2410.01407) | [AgriCLIP](https://github.com/umair1221/AgriCLIP/tree/main) | COLING'25|
Visual-Spatial Perception|Novel Object Detection| [Enhancing Novel Object Detection via Cooperative Foundational Models](https://arxiv.org/abs/2311.12068) | [CFM](https://github.com/rohit901/cooperative-foundational-models)|WACV'25|
Visual-Spatial Perception|Understanding Vision Models's Generalization| [ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes](https://arxiv.org/abs/2403.04701) | [ObjectCompose](https://github.com/Muhammad-Huzaifaa/ObjectCompose)|ACCV'24-Oral|
Adversarial Machine Learning| Volumetric Medical Segmentation | [On Evaluating Adversarial Robustness of Volumetric Medical Segmentation Models](https://arxiv.org/abs/2406.08486) | [RVMSM](https://github.com/HashmatShadab/Robustness-of-Volumetric-Medical-Segmentation-Models)|BMVC'24|
Vision-Language Model | Histopathology Representation Learning | [Hierarchical Text-to-Vision Self Supervised Alignment for Improved Histopathology Representation Learning](https://arxiv.org/abs/2403.14616) | [HLSS](https://github.com/Hasindri/HLSS)|MICCAI'24|
Self-Learning | Volumetric Medical Segmentation | [MedContext: Learning Contextual Cues for Efficient Volumetric Medical Segmentation](https://arxiv.org/abs/2402.17725) | [MedContext](https://github.com/hananshafi/MedContext)|MICCAI'24|
Adversarial Machine Learning | Adversarial Attack| [BAPLe: Backdoor Attacks on Medical Foundational Models using Prompt Learning](https://arxiv.org/abs/2408.07440) | [baple](https://github.com/asif-hanif/baple)|MICCAI'24|
Adversarial Machine Learning | Certifiable Adversarial Defense | [PromptSmooth: Certifying Robustness of Medical Vision-Language Models via Prompt Learning](https://arxiv.org/abs/2408.16769) | [promptsmooth](https://github.com/nhussein/promptsmooth)|MICCAI'24|
Vision-Language Model | Composed Video Retrieval | [Composed Video Retrieval via Enriched Context and Discriminative Embeddings](https://arxiv.org/abs/2403.16997) | [composed-video-retrieval](https://github.com/OmkarThawakar/composed-video-retrieval)|CVPR'24|
Self-Learning | Multi-Spectral Satellite Imagery | [Rethinking Transformers Pre-training for Multi-Spectral Satellite Imagery](https://arxiv.org/abs/2403.05419)|[satmae_pp](https://github.com/techmn/satmae_pp)|CVPR'24|
Vision-Language Model | Video grounding | [Video-GroundingDINO: Towards Open-Vocabulary Spatio-Temporal Video Grounding](https://arxiv.org/abs/2401.00901)|[Video-GroundingDINO](https://github.com/TalalWasim/Video-GroundingDINO)|CVPR'24|
Multi-modal Large Language Model|  VLM for Remote Sensing | [Geochat: Grounded large vision-language model for remote sensing](https://arxiv.org/abs/2311.15826) | [GeoChat](https://github.com/mbzuai-oryx/GeoChat)|CVPR'24|
Text-to-Image Model| Leaverging LLM to generate complex scenes (Zero-Shot) | [LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts](https://arxiv.org/abs/2310.10640) | [llmblueprint](https://github.com/hananshafi/llmblueprint)| ICLR'24|
Vision-Language Model | Self-structural Alignment of Foundational Models (Zero-Shot) | [Towards Realistic Zero-Shot Classification via Self Structural Semantic Alignment](https://arxiv.org/abs/2308.12960) | [S3A](https://github.com/sheng-eatamath/S3A) | AAAI'24-Oral| 
Vision-Language Model | Test-Time Alignment of Foundational Models (Zero-Shot) | [Align Your Prompts: Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization](https://arxiv.org/abs/2311.01459) | [PromptAlign](https://github.com/jameelhassan/PromptAlign) | NeurIPS'23|
Vision-Language Model | Regulating Foundational Models| [Self-regulating Prompts: Foundational Model Adaptation without Forgetting](https://arxiv.org/abs/2307.06948)|[PromptSRC](https://github.com/muzairkhattak/PromptSRC)|ICCV'23|
Visual-Spatial and Temporal Perception| Video Recognition| [Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition](https://arxiv.org/abs/2307.06947)| [Video-FocalNets](https://github.com/TalalWasim/Video-FocalNets)| ICCV'23
Vision-Language Model| Face Anti-spoofing | [FLIP: Cross-domain Face Anti-spoofing with Language Guidance](https://muzammal-naseer.com/TBA)|[FLIP](https://github.com/koushiksrivats/FLIP)| ICCV'23
Adversarial Machine Learning| Adversarial Training | [Frequency Domain Adversarial Training for Robust Volumetric Medical Segmentation](https://arxiv.org/abs/2307.07269)|[VAFA](https://github.com/asif-hanif/vafa)|MICCAI'23
Adversarial Machine Learning |Facial Privacy| [CLIP2Protect: Protecting Facial Privacy Using Text-Guided Makeup via Adversarial Latent Search](https://arxiv.org/abs/2306.10008)|[Clip2Protect](https://github.com/fahadshamshad/Clip2Protect)|CVPR'23
Vision-Language Model | Video Recognition (Zero-shot)| [Vita-CLIP: Video and text adaptive CLIP via Multimodal Prompting](https://arxiv.org/abs/2304.03307)|[Vita-CLIP](https://github.com/TalalWasim/Vita-CLIP)|CVPR'23|
Self-Learning | Image Recognition (Category Discovery)| [PromptCAL for Generalized Novel Category Discovery](https://arxiv.org/abs/2212.05590)|[PromptCAL](https://github.com/sheng-eatamath/PromptCAL)|CVPR'23|
Adversarial Machine Learning | Adversarial Attack | [Boosting Adversarial Transferability using Dynamic Cues](https://openreview.net/forum?id=SZynfVLGd5) | [DCViT-AT](https://github.com/Muzammal-Naseer/DCViT-AT)|ICLR'23|
Self-Learning| Video Recognition | [Self-Supervised Video Transformer](https://openaccess.thecvf.com/content/CVPR2022/html/Ranasinghe_Self-Supervised_Video_Transformer_CVPR_2022_paper.html)| [SVT](https://github.com/kahnchana/svt)|CVPR'22-Oral|
Adversarial Machine Learning | Adversarial Defense | [Stylized Adversarial Training ](https://ieeexplore.ieee.org/document/9895320)| [SAT](https://github.com/Muzammal-Naseer/SAT)|IEEE-TPAMI'22|
Adversarial Machine Learning| Adversarial Attack| [Adversarial Pixel Restoration as a Pretext Task for Transferable Perturbations](https://arxiv.org/abs/2207.08803)|[ARP](https://github.com/HashmatShadab/APR)|BMVC'22-Oral|
Visual-Spatial Perception| Image Recognition | [How to Train Vision Transformer on Small-scale Datasets?](https://arxiv.org/abs/2210.07240v1)| [VSSD](https://github.com/hananshafi/vits-for-small-scale-datasets) |BMVC'22|
Self-Learning| Image Recognition (Domain Generalization) | [Self-Distilled Vision Transformer for Domain Generalization](https://openaccess.thecvf.com/content/ACCV2022/html/Sultana_Self-Distilled_Vision_Transformer_for_Domain_Generalization_ACCV_2022_paper.html)|[SDViT](https://github.com/maryam089/SDViT) | ACCV'22-Oral|
Visual-Spatial Perception | Understanding Vision Transformer| [Intriguing Properties of Vision Transformers](https://openreview.net/forum?id=o2mbl-Hmfgd)|[IPViT](https://github.com/Muzammal-Naseer/IPViT)| NeurIPS'21-Spotlight|
Adversarial Machine Learning  | Adversarial Attack | [On Improving Adversarial Transferability of Vision Transformers](https://openreview.net/forum?id=D6nH3719vZy)|[ATViT](https://github.com/Muzammal-Naseer/ATViT)|ICLR'21-Spotlight|
Adversarial Machine Learning  | Adversarial Attack | [On Generating Transferable Targeted Perturbations](https://openaccess.thecvf.com/content/ICCV2021/html/Naseer_On_Generating_Transferable_Targeted_Perturbations_ICCV_2021_paper.html)| [TTP](https://github.com/Muzammal-Naseer/TTP) |ICCV'21|
Visual-Spatial Perception | Image Recognition | [Orthogonal Projection Loss ](https://openaccess.thecvf.com/content/ICCV2021/html/Ranasinghe_Orthogonal_Projection_Loss_ICCV_2021_paper.html)| [OPL](https://github.com/kahnchana/opl)|ICCV'21|
Adversarial Machine Learning | Adversarial Defense | [A Self-supervised Approach for Adversarial Robustness](https://openaccess.thecvf.com/content_CVPR_2020/html/Naseer_A_Self-supervised_Approach_for_Adversarial_Robustness_CVPR_2020_paper.html)|[NRP](https://github.com/Muzammal-Naseer/NRP)|CVPR'20-Oral|
Adversarial Machine Learning | Adversarial Attack | [Cross-Domain Transferability of Adversarial Perturbations](https://papers.nips.cc/paper/2019/hash/99cd3843754d20ec3c5885d805db8a32-Abstract.html) | [CDA](https://github.com/Muzammal-Naseer/Cross-Domain-Perturbations)|NeurIPS'19|
Adversarial Machine Learning | Adversarial Defense | [Local Gradients Smoothing: Defense Against Localized Adversarial Attacks](https://arxiv.org/abs/1807.01216) | [LGS](https://github.com/Muzammal-Naseer/LGS)| WACV'19|
